{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tensorboard_logger import configure, log_value\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.utils as utils\n",
    "\n",
    "from models.generator_srgan import Generator\n",
    "from models.discriminator_srgan import Discriminator\n",
    "\n",
    "from utils.utils_sr import TrainDataset, DevDataset, to_image\n",
    "\n",
    "import random\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 69\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch_pretrain = 2\n",
    "use_tensorboard = True\n",
    "\n",
    "crop_size = 512\n",
    "num_epochs = 10\n",
    "batch_size = 4\n",
    "#train_set='./data/archive/anime_face'\n",
    "train_set='./data/archive/small_data'\n",
    "dev_set = './data/archive/dev_anime_face'\n",
    "check_point=-1\n",
    "\n",
    "input_size = crop_size\n",
    "n_epoch = num_epochs\n",
    "batch_size = batch_size\n",
    "check_point = check_point\n",
    "\n",
    "check_point_path = 'utils/cp/'\n",
    "if not os.path.exists(check_point_path):\n",
    "\tos.makedirs(check_point_path)\n",
    "\n",
    "train_set = TrainDataset(train_set, crop_size=input_size, upscale_factor=8)\n",
    "train_loader = DataLoader(dataset=train_set, num_workers=2, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dev_set = DevDataset(dev_set, upscale_factor=8)\n",
    "dev_loader = DataLoader(dataset=dev_set, num_workers=1, batch_size=1, shuffle=False)\n",
    "\n",
    "mse = nn.MSELoss()\n",
    "bce = nn.BCELoss()\n",
    "\t\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "\tprint ('##################USING CPU####################')\n",
    "\n",
    "netG = Generator()\n",
    "print('# generator parameters:', sum(param.numel() for param in netG.parameters()))\n",
    "netD = Discriminator()\n",
    "print('# discriminator parameters:', sum(param.numel() for param in netD.parameters()))\n",
    "\n",
    "# pass to gpu if available\n",
    "netG.to(device)\n",
    "netD.to(device)\n",
    "mse.to(device)\n",
    "bce.to(device)\n",
    "\n",
    "if use_tensorboard:\n",
    "\tconfigure('log', flush_secs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(netG, (3,64,64))\n",
    "summary(netD, (3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_batch = next(iter(train_loader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-train generator using only MSE loss\n",
    "if check_point == -1:\n",
    "\toptimizerG = optim.Adam(netG.parameters())\n",
    "\tfor epoch in range(1, n_epoch_pretrain + 1):\n",
    "\t\ttrain_bar = tqdm(train_loader)\n",
    "\t\t\n",
    "\t\tnetG.train()\n",
    "\t\t\n",
    "\t\tcache = {'g_loss': 0}\n",
    "\n",
    "\t\tfor lowres, real_img_hr in train_bar:\n",
    "\t\t\treal_img_hr = real_img_hr.to(device)\n",
    "\t\t\t\t\n",
    "\t\t\tlowres = lowres.to(device)\n",
    "\t\t\t\t\n",
    "\t\t\tfake_img_hr = netG(lowres)\n",
    "\n",
    "\t\t\t# Train G\n",
    "\t\t\tnetG.zero_grad()\n",
    "\t\t\t\n",
    "\t\t\timage_loss = mse(fake_img_hr, real_img_hr)\n",
    "\t\t\tcache['g_loss'] += image_loss\n",
    "\t\t\t\n",
    "\t\t\timage_loss.backward()\n",
    "\t\t\toptimizerG.step()\n",
    "\n",
    "\t\t\t# Print information by tqdm\n",
    "\t\t\ttrain_bar.set_description(desc='[%d/%d] Loss_G: %.4f' % (epoch, n_epoch_pretrain, image_loss))\n",
    "\t\t\t\n",
    "\t# Save model parameters\t\n",
    "\ttorch.save(netG.state_dict(), 'utils/cp/netG_epoch_pre_gpu.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerG = optim.Adam(netG.parameters())\n",
    "optimizerD = optim.Adam(netD.parameters())\n",
    "\n",
    "if check_point != -1:\n",
    "\tnetG.load_state_dict(torch.load('utils/cp/netG_epoch_' + str(check_point) + '_gpu.pth'))\n",
    "\tnetD.load_state_dict(torch.load('utils/cp/netD_epoch_' + str(check_point) + '_gpu.pth'))\n",
    "\toptimizerG.load_state_dict(torch.load('utils/cp/optimizerG_epoch_' + str(check_point) + '_gpu.pth'))\n",
    "\toptimizerD.load_state_dict(torch.load('utils/cp/optimizerD_epoch_' + str(check_point) + '_gpu.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "\tfor epoch in range(1 + max(check_point, 0), n_epoch + 1 + max(check_point, 0)):\n",
    "\t\ttrain_bar = tqdm(train_loader)\n",
    "\t\t\n",
    "\t\tnetG.train()\n",
    "\t\tnetD.train()\n",
    "\t\t\n",
    "\t\tcache = {'mse_loss': 0, 'adv_loss': 0, 'g_loss': 0, 'd_loss': 0}\n",
    "\n",
    "\n",
    "\t\tfor lowres, real_img_hr in train_bar:\n",
    "\t\t\t#print ('lr size : ' + str(data.size()))\n",
    "\t\t\t#print ('hr size : ' + str(target.size()))\n",
    "\t\t\treal_img_hr = real_img_hr.to(device)\n",
    "\t\t\tlowres = lowres.to(device)\n",
    "\t\t\t\n",
    "\t\t\t#######################################################\n",
    "\t\t\t# Train Discriminator\n",
    "\t\t\t#######################################################\n",
    "\n",
    "\t\t\t#if not check_grads(netD, 'D'):\n",
    "\t\t\t#\treturn\n",
    "\t\t\tnetD.zero_grad()\n",
    "\t\t\t\n",
    "\t\t\tlogits_real = netD(real_img_hr)\n",
    "\t\t\tlogits_fake = netD(netG(lowres).detach())\n",
    "\t\t\t\n",
    "\t\t\t# Lable smoothing\n",
    "\t\t\treal = torch.tensor(torch.rand(logits_real.size())*0.25 + 0.85)\n",
    "\t\t\tfake = torch.tensor(torch.rand(logits_fake.size())*0.15)\n",
    "\t\t\t\n",
    "\t\t\t# Lable flipping\n",
    "\t\t\tprob = (torch.rand(logits_real.size()) < 0.05)\n",
    "\t\t\t\n",
    "\t\t\t#print ('logits real size : ' + str(logits_real.size()))\n",
    "\t\t\t#print ('logits fake size : ' + str(logits_fake.size()))\n",
    "\t\t\t\n",
    "\t\t\treal = real.to(device)\n",
    "\t\t\tfake = fake.to(device)\n",
    "\t\t\tprob = prob.to(device)\n",
    "\t\t\t\t\n",
    "\t\t\treal_clone = real.clone()\n",
    "\t\t\treal[prob] = fake[prob]\n",
    "\t\t\tfake[prob] = real_clone[prob]\n",
    "\t\t\t\n",
    "\t\t\td_loss = bce(logits_real, real) + bce(logits_fake, fake)\n",
    "\t\t\t\n",
    "\t\t\tcache['d_loss'] += d_loss.item()\n",
    "\t\t\t\n",
    "\t\t\td_loss.backward()\n",
    "\t\t\toptimizerD.step()\n",
    "\n",
    "\t\t\t#######################################################\n",
    "\t\t\t# Train Generator\n",
    "\t\t\t#######################################################\n",
    "\n",
    "\t\t\t#if not check_grads(netG, 'G'):\n",
    "\t\t\t#\treturn\n",
    "\t\t\tnetG.zero_grad()\n",
    "\t\t\t\n",
    "\t\t\tfake_img_hr = netG(lowres)\n",
    "\t\t\timage_loss = mse(fake_img_hr, real_img_hr)\n",
    "\t\t\t\n",
    "\t\t\tlogits_fake_new = netD(fake_img_hr)\n",
    "\t\t\tadversarial_loss = bce(logits_fake_new, torch.ones_like(logits_fake_new))\n",
    "\t\t\t\n",
    "\t\t\tg_loss = image_loss + 1e-2*adversarial_loss\n",
    "\n",
    "\t\t\tcache['mse_loss'] += image_loss.item()\n",
    "\t\t\tcache['adv_loss'] += adversarial_loss.item()\n",
    "\t\t\tcache['g_loss'] += g_loss.item()\n",
    "\n",
    "\t\t\tg_loss.backward()\n",
    "\t\t\toptimizerG.step()\n",
    "\n",
    "\t\t\t# Print information by tqdm\n",
    "\t\t\ttrain_bar.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f = %.4f + %.4f' % (epoch, n_epoch, d_loss, g_loss, image_loss, adversarial_loss))\n",
    "\t\t\n",
    "\t\tif use_tensorboard:\n",
    "\t\t\tlog_value('d_loss', cache['d_loss']/len(train_loader), epoch)\n",
    "\t\t\n",
    "\t\t\tlog_value('mse_loss', cache['mse_loss']/len(train_loader), epoch)\n",
    "\t\t\tlog_value('adv_loss', cache['adv_loss']/len(train_loader), epoch)\n",
    "\t\t\tlog_value('g_loss', cache['g_loss']/len(train_loader), epoch)\n",
    "\t\t\n",
    "\t\t# Save model parameters\t\n",
    "\t\ttorch.save(netG.state_dict(), 'utils/cp/netG_epoch_%d_smallData.pth' % (epoch))\n",
    "\t\tif epoch%5 == 0:\n",
    "\t\t\ttorch.save(netD.state_dict(), 'utils/cp/netD_epoch_%d_smallData.pth' % (epoch))\n",
    "\t\t\ttorch.save(optimizerG.state_dict(), 'utils/cp/optimizerG_epoch_%d_smallData.pth' % (epoch))\n",
    "\t\t\ttorch.save(optimizerD.state_dict(), 'utils/cp/optimizerD_epoch_%d_smallData.pth' % (epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "check_point = 5\n",
    "netG.load_state_dict(torch.load('utils/cp/netG_epoch_' + str(check_point) + '_gpu.pth'))\n",
    "netD.load_state_dict(torch.load('utils/cp/netD_epoch_' + str(check_point) + '_gpu.pth'))\n",
    "optimizerG.load_state_dict(torch.load('utils/cp/optimizerG_epoch_' + str(check_point) + '_gpu.pth'))\n",
    "optimizerD.load_state_dict(torch.load('utils/cp/optimizerD_epoch_' + str(check_point) + '_gpu.pth'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\t# Visualize results\n",
    "\twith torch.no_grad():\n",
    "\t\tnetG.eval()\n",
    "\t\tout_path = 'utils/vis/'\n",
    "\t\tif not os.path.exists(out_path):\n",
    "\t\t\tos.makedirs(out_path)\n",
    "\t\t\t\n",
    "\t\tdev_bar = tqdm(dev_loader)\n",
    "\t\tvaling_results = {'mse': 0, 'batch_sizes': 0}\n",
    "\t\tdev_images = []\n",
    "\t\tfor val_lr, val_hr_restore, val_hr in dev_bar:\n",
    "\t\t\tbatch_size = val_lr.size(0)\n",
    "\t\t\tlr = val_lr\n",
    "\t\t\thr = val_hr\n",
    "\t\t\tlr = lr.to(device)\n",
    "\t\t\thr = hr.to(device)\n",
    "\t\t\tsr = netG(lr)\n",
    "\t\t\t\n",
    "\t\t\tdev_bar.set_description(desc='[converting LR images to SR images]')\n",
    "\t\t\t\n",
    "\t\t\t# Avoid out of memory crash on 8G GPU\n",
    "\t\t\tif len(dev_images) < 60 :\n",
    "\t\t\t\tdev_images.extend([to_image()(val_hr_restore.squeeze(0)), to_image()(hr.data.cpu().squeeze(0)), to_image()(sr.data.cpu().squeeze(0))])\n",
    "\t\t\n",
    "\t\tdev_images = torch.stack(dev_images)\n",
    "\t\tdev_images = torch.chunk(dev_images, dev_images.size(0) // 3)\n",
    "\t\t\n",
    "\t\tdev_save_bar = tqdm(dev_images, desc='[saving training results]')\n",
    "\t\tindex = 1\n",
    "\t\tfor image in dev_save_bar:\n",
    "\t\t\timage = utils.make_grid(image, nrow=3, padding=5)\n",
    "\t\t\tutils.save_image(image, out_path + 'smallData_epoch_%d_index_%d.png' % (epoch, index), padding=5)\n",
    "\t\t\tindex += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32aaecebd078ebf0fad58c11ce872e322c9fff2b8f0b0f5a9c84d62363eabb98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
